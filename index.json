[{"categories":["How-to","technology"],"content":"I started exploring and using Jupyter Notebook earlier this year for a project based on opensource enablement, licensing and operate first. This is the first time ever I was working with a notebook and apparently had to start from sratch right from understanding how it works, how it needs to be installed and finally how it is to be pushed to a repo and publish the work. In the process of exploring the tool, I went throught quite a handful of articles and videos. Everyone‚Äôs way was a bit different than the other and there was no way correct or proper to work around this. Amongst all, I found the below way to be the most effective and clean and hence thought of penning down the learnings create a how-to guide on installing and working with Jupyter Notebooks. This article is written based on a MacOS. Haven‚Äôt tried on a linux machine. Jupyter Notebook = JN //for ease of writing Prerequisites: Install python3 package ","date":"2022-06-29","objectID":"/jupyternotebooks/:0:0","tags":["JupyterNotebooks","How-to"],"title":"Getting started with Jupyter Notebooks","uri":"/jupyternotebooks/"},{"categories":["How-to","technology"],"content":"Install and launch JN First, let‚Äôs create a virtual environment to install JN parth@mac Desktop % python3 -m venv jupyter parth@mac Desktop % ls jupyter This creates a folder called jupyter in the current dir which has a python virtual env. To turn the venv on: parth@mac Desktop % source ~/jupyter/bin/activate (jupyter) parth@mac Desktop % The jupyter in parenthesis lets us know that we are in our python jupyter virtual environment. NOTE: This needs to be turned everytime you need to work with jupyter notebooks. Now, let‚Äôs install the jupyter notebook pkg (jupyter) parth@mac Desktop % pip3 install jupyter notebook This installs the jupyter and notebook packages. Creating another dir where I will be launching the JN from and where I can create pages. (jupyter) parth@mac Desktop % mkdir JupyterNotebooks (jupyter) parth@mac Desktop % cd JupyterNotebooks (jupyter) parth@mac JupyterNotebooks % pwd /Users/parth/Desktop/JupyterNotebooks Launching JN now (jupyter) parth@mac JupyterNotebooks % jupyter notebook . This runs a kernel process on the terminal and launches JN from the JupyterNotebooks dir in your default web browser. Note All and any work you do can be accessed via localhost and is saved locally. Click on the new button in the brower‚Äôs JN page to create a new page. The page can be a simple text file, a python file with .ipynb extension or markdown page with .md extention. Any pages you create are now saved in JupyterNotebooks dir. Alright, we have installed and launched JN to create the pages. Now it‚Äôs time we create a bundled book out of the pages and upload it in a git repo and publish the book. ","date":"2022-06-29","objectID":"/jupyternotebooks/:1:0","tags":["JupyterNotebooks","How-to"],"title":"Getting started with Jupyter Notebooks","uri":"/jupyternotebooks/"},{"categories":["How-to","technology"],"content":"Build and Publish the book Follow the steps mentioned here https://jupyterbook.org/en/stable/start/overview.html Install Jupyter Book pip3 install -U jupyter-book Tip Jupyter Book comes bundled with a lightweight sample book to help you understand a book‚Äôs structure. Create a sample book by running the following command: $ jupyter-book create mynewbook/ The name mynewbook can be replaced with any other name and create option will create a skeleton of book for you. Edit/add/modify the pages under this book. Once you are done with creating pages and have configured _toc.yml and _config.yml, it‚Äôs time to build the book. $ jupyter-book build mynewbook/ Use the same build option to re-build the book if you make any new changes. The book is build. Once all the final reviews are done, it can be published in the git repository. Follow the link below to publish the book online. https://jupyterbook.org/en/stable/start/publish.html Checkout some of my works based on Jupyter Notebook Opensource Enablement Opensource Licensing Thank you for reading! ","date":"2022-06-29","objectID":"/jupyternotebooks/:2:0","tags":["JupyterNotebooks","How-to"],"title":"Getting started with Jupyter Notebooks","uri":"/jupyternotebooks/"},{"categories":null,"content":"Hey there! TL;DR: Name: Parth Goswami Let‚Äôs connect on Twitter ","date":"2022-06-26","objectID":"/about/:0:0","tags":null,"title":"About","uri":"/about/"},{"categories":null,"content":"About the website A platform for the community, by the community VistingAuthors Many of my colleagues are avid writers who frequently document their knowledge and experiences. Some of them use their own platforms to publish the information, while others use blogs like Medium and Blogger to publish it. The VisitingAuthors area of this website is an effort to offer one such platform for authors to share their knowledge and ideas. Please check out the site; I hope it will provide you with useful content. UnconventionalContributors We have a diverse range of contributors in the open source community who make contributions in unconventional ways without using any coding or developing expertise, some ways we hear quite often, some not so much. This high-level instructional interview series should be beneficial to anyone who wants to start contributing to open source. One such forum is the UnconventionalContributors series, which is designed for aspiring and emerging contributors to get involved with open source communities. ","date":"2022-06-26","objectID":"/about/:1:0","tags":null,"title":"About","uri":"/about/"},{"categories":null,"content":"About the author I am a Customer Enablement Engineer working for Cloudera on the Professional Services Team in Bengaluru, India. My interests are in Kubernetes, cloud, and cloud native related projects. I like to contribute to OpenSource in any possible way. The opinions stated here are my own, not necessarily those of my company. ","date":"2022-06-26","objectID":"/about/:2:0","tags":null,"title":"About","uri":"/about/"},{"categories":null,"content":"About copyright All original articles on this site are protected by the Creative Commons Attribution-NonCommercial 4.0 License/CC BY-NC 4.0 . Copyright statement You are free to: Share ‚Äî copy and redistribute the material in any medium or format Adapt ‚Äî remix, transform, and build upon the material The licensor cannot revoke these freedoms as long as you follow the license terms. Any individual or media should abide by the following copyright requirements when reproducing the original content of this site (including text, self-made images, and photographic works): indicate reprint indicate the source as the site domain name ( parthgoswami.com ), or the full URL where the reprinted content is located NonCommercial ‚Äî You may not use the material for commercial purposes. Except for original works, most of the pictures on this site come from the Internet. The original copyright owner of such pictures may request this site to stop using relevant pictures at any time and for any reason, including pictures edited by this site (such as annotated descriptions). ","date":"2022-06-26","objectID":"/about/:3:0","tags":null,"title":"About","uri":"/about/"},{"categories":null,"content":"Come, say hello!üëãüèª Get in touch with us on Twitter, LinkedIn or send me an email. We would love to talk with you. ","date":"2022-06-26","objectID":"/about/:4:0","tags":null,"title":"About","uri":"/about/"},{"categories":["How-to","VisitingAuthors","technology"],"content":" If you start from the bare metal layer and go right up until the container layer through virtualization, base OS and the container engine, you would notice that networking runs throughout the stack. Networking is the backbone of any infrastructure. Hence, understanding the networking concepts becomes very important and if we are talking about cloud computing, it becomes ever more important. In this article, I will be discussing how networking works in the cloud computing. For clarity, this article focuses on Virtual Private Cloud[VPC], a networking service provided by Amazon Web Services. Let‚Äôs dive into it! ","date":"2022-06-26","objectID":"/decoding_vpc/:0:0","tags":["How-to","technology","aws","VPC","networking","ShreyaDhange","VisitingAuthors"],"title":"How does VPC work?","uri":"/decoding_vpc/"},{"categories":["How-to","VisitingAuthors","technology"],"content":"What is VPC? VPC stands for Virtual Private Cloud and is one of the most fundamental and widely used AWS service which provides a virtual network dedicated for the AWS environments. It is logically isolated from the other virtual networks in the cloud and exists within a single region. VPC allows for more control of AWS Cloud Network with extra layer of security. ","date":"2022-06-26","objectID":"/decoding_vpc/:1:0","tags":["How-to","technology","aws","VPC","networking","ShreyaDhange","VisitingAuthors"],"title":"How does VPC work?","uri":"/decoding_vpc/"},{"categories":["How-to","VisitingAuthors","technology"],"content":"How does VPC works? VPC cannot talk directly to the internet. For that we need Internet Gateway to talk to the internet. Internet Gateway is used to allow resources (subnets) in your VPC to access Internet. VPC can have multiple subnets and these subnets can be public facing or private. Subnets are the the spaces where your applications are running. Subnets are been decided by CIDR( Classless inter-domain routing). Public subnets are the ones that are accessible to the internet and Private subnets are the ones that are not accessible by the internet. For example: Amazon Shopping Website, you cannot access the database of this website but you can access the application of Amazon Shopping Website . This means that the application is running on public subnet and the database is running on private subnet. We decide these public and private subnets using Route Table. Route table is the place where you put all the entries of these public and private subnets i.e. IP address. Every VPC has one default Route table. All subnets that you launch will be a part of this Route table. Everything will go into the Route table i.e. public subnet, private subnet and the internet gateway which means anyone who is coming can access my private subnet which is dangerous. To over come this we use different Route tables i.e. we will make different public route table and different private route table i.e. the internet gateway can access my public subnet and not the private subnet. All the new entries of the subnet will enter into default Route table and whenever you want you can move these entries into public or private subnets. Internet gateway can access the public subnet and public subnet will communicate with the private subnet. If the private subnet wants to talk to the internet but it cannot communicate directly to the internet that time we will use NAT. NAT, Network Address Translation, refers to the proxy server. Private subnet will talk to the internet through NAT but internet will not talk directly to the private subnet, it will first communicate with public subnet and then public subnet will talk to the private subnet. VPC reference diagram ","date":"2022-06-26","objectID":"/decoding_vpc/:2:0","tags":["How-to","technology","aws","VPC","networking","ShreyaDhange","VisitingAuthors"],"title":"How does VPC work?","uri":"/decoding_vpc/"},{"categories":["How-to","VisitingAuthors","technology"],"content":"What is CIDR? CIDR is Classless inter-domain routing. This will decide how many subnets you want to launch in a machine (VPC). Inside these subnets we can launch our machines. It contains the range of IPs i.e. IPv4 and IPv6. IPv6 - 128 bits IPv4 - 32 bits x.x.x.x/16 - x.x.x.x/28 (choose any value between this CIDR range) Suppose, 10.0.0.0/16 = 32-16=16 ==\u003e 2^16= 65536 (65536 IP can be launched in 1 VPC of 16 CIDR value) 10.0.0.0/24 = 32-24= 8 ==\u003e 2^8= 256 10.0.0.0/28= 32-28= 4 ==\u003e 2^4= 16 A minimum 16 subnets and maximum 65536 subnets can be launched in 1 VPC. If your requirements is for more subnets then choose lower CIDR value and if requirement is less then choose higher CIDR value. ","date":"2022-06-26","objectID":"/decoding_vpc/:3:0","tags":["How-to","technology","aws","VPC","networking","ShreyaDhange","VisitingAuthors"],"title":"How does VPC work?","uri":"/decoding_vpc/"},{"categories":["How-to","VisitingAuthors","technology"],"content":"Benefits of VPC Define custom networks. Assigns static private ipv4 addresses to the instances. Define network interfaces and attach one or more network interface to the instance. Define routing between different subnets. Define internet access for the subnets. Define your network security by allowing/denying the traffic. In this article, we discussed what VPC is and how does it work along with some of its benefits. In the next article, I will be discussing how to configure VPC in AWS and the steps to delete it once we are done tinkering with it. Stay tuned for the next article! Shreya Dhange is a Technical Training Developer at Red Hat, who likes to explore and learn new technologies and share her knowledge by writing articles. She has completed her Masters in Computer Science and has gained award for her exemplary academic performance. She has been engaged in creating and delivering content in the cloud and linux space. She can be reached out LinkedIn or via email. ","date":"2022-06-26","objectID":"/decoding_vpc/:4:0","tags":["How-to","technology","aws","VPC","networking","ShreyaDhange","VisitingAuthors"],"title":"How does VPC work?","uri":"/decoding_vpc/"},{"categories":["How-to","VisitingAuthors","technology"],"content":"Consider a scenerio: We have setup a VPC for the instances which are in the same range. The Public instance is having an internet connection and Private instance does not having an internet connection. Inside Public instance we have S3 bucket endpoint to which users will have the access to upload/download images and videos. The EC2 instances have an ELB (Elastic Load Balancer) attached with an Alarm set to it. The EC2 instances will have IAM roles attached to it having roles set like AWSS3FullAccess, AWSRekognitionFullAccess and AWSElasticTranscoderFullAccess. ","date":"2022-06-26","objectID":"/aws_rekognition/:1:0","tags":["How-to","technology","AWS","aws rekognition","aws transcoder","ShreyaDhange","VisitingAuthors"],"title":"How to configure AWS Rekognition and AWS Transcoder","uri":"/aws_rekognition/"},{"categories":["How-to","VisitingAuthors","technology"],"content":"Steps: Private instance will have NAT connectivity with Public instance which will open a browser with the endpoint given to the user to access S3 bucket uploads an image an request for image recognition. Inside EC2 run this command to get the output: aws rekognition detect-labels --image \"{\\\"S3Object\\\":{\\\"Bucket\\\":\\\"bucketname\\\",\\\"Name\\\":\\\"image.png\\\"}}\" --region us-east-1 The output of the image recognition will be stored in Amazon RDS. If the user wants a video to be converted to the version which can be accessible via phone or pc can upload the video in S3 Bucket and by setting up a pipeline in AWS Transcoder the user will be notified about the process completion and the user can further request for image/video recognition. The user having internet connection will access S3 Bucket with the endpoint provided and can further request for the AWS Rekognition. Procedure is same as above. ","date":"2022-06-26","objectID":"/aws_rekognition/:2:0","tags":["How-to","technology","AWS","aws rekognition","aws transcoder","ShreyaDhange","VisitingAuthors"],"title":"How to configure AWS Rekognition and AWS Transcoder","uri":"/aws_rekognition/"},{"categories":["How-to","VisitingAuthors","technology"],"content":"Configuration: First step is to configure VPC: 1.1 Create VPC with the name MyVPC: 1.2 Create 3 Subnets with the name Public, Public1, Private: 1.3 Create a separate Route table with names PublicRT and PrivateRT and place the subnets with the respective route table: 1.4 Create a Gateway with the name MyGateway: Create three EC2 instances and attach them with MyVPC as given below : Create IAM roles the instances: 3.1 Create IAM roles for Public Instance with respective policy as shown below: 3.2 Create IAM role for Private instance which holds RDS policy (optional) : Create S3 bucket as follows: 4.1 Create 2 buckets with the name inputbucket12 and outputbucket12: 4.2 The inputbucket12 will be used to upload images and videos: Setup for AWS Image Rekognition in Public instance using cli mode: Setting up AWS Transcoder for video converter: 6.1 Create Pipeline as given below: 6.2 Create job for the Pipeline: 6.3 Output of the video will be shown in outputbucket12: Shreya Dhange is a Technical Training Developer at Red Hat, who likes to explore and learn new technologies and share her knowledge by writing articles. She has completed her Masters in Computer Science and has gained award for her exemplary academic performance. She has been engaged in creating and delivering content in the cloud and linux space. She can be reached out LinkedIn or via email. ","date":"2022-06-26","objectID":"/aws_rekognition/:3:0","tags":["How-to","technology","AWS","aws rekognition","aws transcoder","ShreyaDhange","VisitingAuthors"],"title":"How to configure AWS Rekognition and AWS Transcoder","uri":"/aws_rekognition/"},{"categories":["community","UnconventionalContributors"],"content":"We have many diverse contributors here at Red Hat that help upstream communities in unconventional ways that don‚Äôt require any coding or development skills. Starting with a non-code contribution can help anyone overcome the sense of failure and not being good enough, and it can also serve as a springboard for our open source adventure. This article aims to highlight some non-code open source contributions that anyone can make right now to get started contributing. For this month‚Äôs edition, we talked about the Mozilla and Wikipedia with Prathamesh Chavan. Can you tell us some background about you, what your journey has been at Red Hat, and what you do today? I am Prathamesh Chavan and I completed my engineering degree in information technology in 2016 and joined Red Hat as an intern on October 3rd, 2016. I was converted to full-time employment in 2017 and joined the Technical Chat Support team as an Associate Customer Support Specialist-Technical. As a Technical Support Engineer, I worked on queries related to subscription management, and it was in March of 2020 when I joined the then CEE Operations team as a Technical Project Coordinator. As of today, I am an Associate Technical Project Manager in the CEE Strategic Solutions team, and my day- to-day responsibilities involve managing agile projects. Share your experience in becoming a community contributor. An open source contribution is a selfless effort to do something good. After becoming an open source contributor, I was able to explore the various steps of the software development life cycle. I learned how it provides a basis for project planning, scheduling, and estimating, as well as how it raises project planning visibility among all the stakeholders. I felt very empowered and motivated due to the open source ideology, and this has helped me in building a ‚Äúnever stop, never-give-up‚Äù attitude. What project(s) have you contributed to? How did your contribution journey start? I have contributed to Mozilla projects and Wikipedia. I joined the technical club at my university as an events blogger, and it was only after that that I came to know about the various open source communities and the contribution pathways. In my initial days, I read a couple of articles in the Mozilla Developers Network portal related to the Mozilla Firefox browser and started to suggest edits wherever needed. Later, I started localizing the Mozilla articles, which were written in English, into my native language, Marathi. Over the next couple of months, I got acquainted with the Mozilla Firefox browser and started helping other users fix their issues with the browser. I also believe most open source organizations consider answering other people‚Äôs questions on Quora or Reddit to be a useful contribution. I started joining and reading discussions on threads and learned a lot through that. So, I always recommend to people that if we notice a question and know the solution, we may try to help the person who asked it by answering it, and our responses will be counted as contributions to the project. Sometimes, assuming one doesn‚Äôt know the perfect solution to the problem, simply helping others comprehend why the problem arises may be enough to allow them to come up with their own solution. You may help manage the discussion threads or community chat channels by answering questions about problems on GitHub, opensource.com, Mozilla, etc. In what way(s) have you contributed? As someone who likes talking about open source philosophies and concepts, I decided to start with a documentation-related contribution as a technical writer, where I started writing and reviewing the documentation on the Mozilla Developers Network. Later, I realized that the articles were only written in English, and there was a huge need to localize such articles in the regional languages. I started my contribution by localizing the articles and strings. Due to such contributions, I got some knowledge about how to use the Firefox brows","date":"2022-06-20","objectID":"/prathameshchavan/:0:0","tags":["blogs","community","fedora","mozilla"],"title":"Contributor Blog #1: Pilot","uri":"/prathameshchavan/"},{"categories":["VisitingAuthors","How-to","technology"],"content":"Let us create a dockerfile for deploying the application. In this dockerfile we will use ubuntu image as the base image and then install apache and php above it. Then we will create a MYSQL container which will be connected to our application. ","date":"2022-06-06","objectID":"/dockerizing_lamp_stack_app/:0:0","tags":["How-to","docker","blog","lamp stack","technology","VrindaHegde","VisitingAuthors"],"title":"Dockerizing LAMP Stack Application","uri":"/dockerizing_lamp_stack_app/"},{"categories":["VisitingAuthors","How-to","technology"],"content":"Below is the Dockerfile snippet: # Dockerfile for LAMP Stack installation # Ubuntu 18.04 image FROM ubuntu:18.04 ENV DEBIAN_FRONTEND=noninteractive RUN apt-get update -y RUN apt-get upgrade -y # Install apache RUN apt-get install -y apache2 # Prerequisites for installing php7.3 RUN apt-get install -y software-properties-common RUN add-apt-repository ppa:ondrej/php RUN apt install -y php7.3-fpm # Install php7.3 for this set up RUN apt install -y php7.3 # Extensions of php RUN apt install php7.3-common php7.3-mysql php7.3-xml php7.3-xmlrpc php7.3-curl php7.3-gd php7.3-imagick php7.3-cli php7.3-dev php7.3-imap php7.3-mbstring php7.3-opcache php7.3-soap php7.3-zip php7.3-intl -y # Removing the default index.html page and copying the project code RUN rm -f /var/www/html/index.html COPY . /var/www/html/ # Install ufw RUN apt install ufw -y RUN ufw app list # install library RUN apt-get install libapache2-mod-php7.3 # install additional packages RUN a2dismod mpm_event \u0026\u0026 a2enmod mpm_prefork \u0026\u0026 a2enmod php7.3 # Restart apache RUN service apache2 restart # Provide executable permissions to the code RUN chmod -R 0777 /var/www/html/* RUN chmod -R 0777 /var/* # Change WORKDIR WORKDIR /var/www/html CMD [\"apachectl\",\"-D\",\"FOREGROUND\"] RUN a2enmod rewrite EXPOSE 80 EXPOSE 443 In this dockerfile I have installed php 7.3 version which was required for my application. Use the below command to build the image from the dockerfile: docker build -f dockerfile-lamp-stack.dockerfile . Next let us create the containers to deploy the application. Below is the snippet of docker-compose file: version: '3' networks: lamp-stack-net: external: true volumes: mysql_storage_01: external: true services: lamp_stack: image: lamp_stack_app:v1 privileged: true build: context: path_to_code dockerfile: dockerfile-lamp-stack.dockerfile container_name: app_cont networks: - lamp-stack-net ports: - \"8010:80\" volumes: - path_to_code/:/var/www/html/ mysql_service: image: mysql:5.7.25 container_name: mysql_cont ports: - \"3306:3306\" environment: # MYSQL_ROOT_PASSWORD: '' # MYSQL_ALLOW_EMPTY_PASSWORD : 'yes' MYSQL_ROOT_PASSWORD: root MYSQL_DATABASE: test_db MYSQL_USER: test_user MYSQL_PASSWORD: test@123 networks: - lamp-stack-net restart: always volumes: - path_to_dump_file/:/home/ - mysql_storage_01:/var/lib/mysql In the above docker-compose file we are building the LAMP Stack container and MYSQL container. For the lamp_stack service we need to give the context of the code and place the dockerfile at that loaction in order to build our LAMP Stack image. We are exposing the port 8010 where the application will be served on the browser. Next is mysql_service, where we are creating the mysql container by using MYSQL 5.7 version. In the volumes section we have to use the location to our source code and database dump file respectively on line 25 and 43 respectively. Use the below commands to create network and volumes respectively: docker network create lamp-stack-net docker volume create --name=mysql_storage_01 Now let us create the containers using the below command: docker-compose -f docker-compose-lamp-stack.yml up -d Now check if both the containers are up and running using the below command: docker ps If both the containers are up and running then check on the browser using: \u003cIP\u003e:8010 or localhost:8010 This will serve the default page on the browser. To connect to the database you will need to use the database details in your php config file. Hope this article was helpful. Happy Learing!!! Vrinda Hegde is a DevOps Engineer, who likes to explore orchestration tools and automate the process of deploying containerized applications. She likes to share her findings by writing articles on medium.com. She can be reached out on LinkedIn or via email ","date":"2022-06-06","objectID":"/dockerizing_lamp_stack_app/:1:0","tags":["How-to","docker","blog","lamp stack","technology","VrindaHegde","VisitingAuthors"],"title":"Dockerizing LAMP Stack Application","uri":"/dockerizing_lamp_stack_app/"},{"categories":["VisitingAuthors","How-to","technology"],"content":" Ansible is an open-source configuration management and deployment tool. Below are the steps to run docker container on AWS EC2 instances using Ansible playbook. Create AWS EC2 instances (master and slave) Update the security group of slave exposing port 8080 Install Ansible on master Install python on slave Update /etc/ansible/hosts on master with the slave IP Create a dockerfile which will be used to create customized image Create an ansible playbook with detailed tasks Execute the ansible playbook Check if the docker container is running successfully on the slave machine ","date":"2022-06-03","objectID":"/docker_containters_ansibleaws/:0:0","tags":["How-to","docker","blog","ansible","aws","technology","VrindaHegde","SiyaAmonkar","VisitingAuthors"],"title":"Docker containers using Ansible on AWS","uri":"/docker_containters_ansibleaws/"},{"categories":["VisitingAuthors","How-to","technology"],"content":"Install Ansible on master machine: Execute the below commands to install Ansible on the master machine: sudo apt-get update sudo apt install software-properties-common sudo apt-add-repository ppa:ansible/ansible sudo apt-get install ansible ","date":"2022-06-03","objectID":"/docker_containters_ansibleaws/:1:0","tags":["How-to","docker","blog","ansible","aws","technology","VrindaHegde","SiyaAmonkar","VisitingAuthors"],"title":"Docker containers using Ansible on AWS","uri":"/docker_containters_ansibleaws/"},{"categories":["VisitingAuthors","How-to","technology"],"content":"Install Python on slave machine: Use the below commands to install python on the slave machine: sudo apt-get update sudo apt-get install python On the master machine perform the below steps to create ssh-keygen: cd /home/ubuntu/.ssh ssh-keygen File names id_rsa.pub will be generated after executing ssh-keygen on master machine. on master machine Copy the contents of the id_rsa.pub file and paste it on slave machine inside the authorized_keys file located at /home/ubuntu/.ssh on slave machine ","date":"2022-06-03","objectID":"/docker_containters_ansibleaws/:2:0","tags":["How-to","docker","blog","ansible","aws","technology","VrindaHegde","SiyaAmonkar","VisitingAuthors"],"title":"Docker containers using Ansible on AWS","uri":"/docker_containters_ansibleaws/"},{"categories":["VisitingAuthors","How-to","technology"],"content":"Update the hosts file on master: To establish ssh connection with the slave machine, add the IP of the slave machine on master‚Äôs hosts file. To edit the hosts file use the below command: sudo nano /etc/ansible/hosts Paste the below content at the end of the file: [production] slave ansible_ssh_host=\u003cslave-IP\u003e To verify the ssh connection between the master and slave, execute the below command: output of the ping command on master machine ","date":"2022-06-03","objectID":"/docker_containters_ansibleaws/:3:0","tags":["How-to","docker","blog","ansible","aws","technology","VrindaHegde","SiyaAmonkar","VisitingAuthors"],"title":"Docker containers using Ansible on AWS","uri":"/docker_containters_ansibleaws/"},{"categories":["VisitingAuthors","How-to","technology"],"content":"Creating the code directory on master machine: Create a directory named LAMP_STACK_content at /home/ubuntu/ location on the master machine. Create a dockerfile at this location. ","date":"2022-06-03","objectID":"/docker_containters_ansibleaws/:4:0","tags":["How-to","docker","blog","ansible","aws","technology","VrindaHegde","SiyaAmonkar","VisitingAuthors"],"title":"Docker containers using Ansible on AWS","uri":"/docker_containters_ansibleaws/"},{"categories":["VisitingAuthors","How-to","technology"],"content":"Create a dockerfile: In order to create a customized image we will create a dockerfile with the following contents: # Dockerfile for LAMP Stack installation # Ubuntu 18.04 image FROM ubuntu:18.04 ENV DEBIAN_FRONTEND=noninteractive RUN apt-get update -y RUN apt-get upgrade -y # Install apache RUN apt-get install -y apache2 # Prerequisites for installing php7.3 RUN apt-get install -y software-properties-common RUN add-apt-repository ppa:ondrej/php RUN apt install -y php7.3-fpm # Install php7.3 for this set up RUN apt install -y php7.3 # Extensions of php RUN apt install php7.3-common php7.3-mysql php7.3-xml php7.3-xmlrpc php7.3-curl php7.3-gd php7.3-imagick php7.3-cli php7.3-dev php7.3-imap php7.3-mbstring php7.3-opcache php7.3-soap php7.3-zip php7.3-intl -y # Removing the default index.html page and copying the project code RUN rm -f /var/www/html/index.html COPY . /var/www/html/ # Install ufw RUN apt install ufw -y RUN ufw app list # install library RUN apt-get install libapache2-mod-php7.3 # install additional packages RUN a2dismod mpm_event \u0026\u0026 a2enmod mpm_prefork \u0026\u0026 a2enmod php7.3 # Restart apache RUN service apache2 restart # Provide executable permissions to the code RUN chmod -R 0777 /var/www/html/* RUN chmod -R 0777 /var/* # Change WORKDIR WORKDIR /var/www/html CMD [\"apachectl\",\"-D\",\"FOREGROUND\"] RUN a2enmod rewrite EXPOSE 80 EXPOSE 443 ","date":"2022-06-03","objectID":"/docker_containters_ansibleaws/:5:0","tags":["How-to","docker","blog","ansible","aws","technology","VrindaHegde","SiyaAmonkar","VisitingAuthors"],"title":"Docker containers using Ansible on AWS","uri":"/docker_containters_ansibleaws/"},{"categories":["VisitingAuthors","How-to","technology"],"content":"Create ansible playbook: Create an ansible-playbook-lamp-stack-new.yaml file on master with the below content. --- - hosts: slave become: yes gather_facts: no tasks: - name: create build directory file: path: /root/demo-lamp_stack state: directory owner: root group: root mode: '0755' - name: copy Dockerfile copy: src: /home/ubuntu/LAMP_STACK_content dest: /root/demo-lamp_stack/ owner: root group: root mode: '0644' - name: build and push container image community.docker.docker_image: build: path: /root/demo-lamp_stack/LAMP_STACK_content/ name: dock1998/lamp_stack_new:v1 source: build state: present - name: Running the container community.docker.docker_container: image: dock1998/lamp_stack_new:v1 name: lamp_stack_new_cont state: started ports: \"8080:80\" - name: Tag and push to docker hub community.docker.docker_image: name: dock1998/lamp_stack_new:v1 repository: dock1998/lamp_stack_new:v2 push: yes source: local state: present ","date":"2022-06-03","objectID":"/docker_containters_ansibleaws/:6:0","tags":["How-to","docker","blog","ansible","aws","technology","VrindaHegde","SiyaAmonkar","VisitingAuthors"],"title":"Docker containers using Ansible on AWS","uri":"/docker_containters_ansibleaws/"},{"categories":["VisitingAuthors","How-to","technology"],"content":"Execute the ansible playbook: Note: Before proceeding ahead with the next steps, you will need to perform docker login using the dockerhub account on the slave machine from where the image will be pushed and pulled. To execute the playbook use the below command: ansible-playbook ansible-playbook-lmap-stack-new.yaml output of the above command on master machine ","date":"2022-06-03","objectID":"/docker_containters_ansibleaws/:7:0","tags":["How-to","docker","blog","ansible","aws","technology","VrindaHegde","SiyaAmonkar","VisitingAuthors"],"title":"Docker containers using Ansible on AWS","uri":"/docker_containters_ansibleaws/"},{"categories":["VisitingAuthors","How-to","technology"],"content":"To verify the execution of playbook: Check if the code directory is copied on the slave machine. output on slave Check if the docker container is running on the slave machine: docker ps output of docker ps on the slave machine Note: If you get permission denied error after executing docker ps command then you need to give permissions to the docker.sock file by executing the below command: chmod -R 0777 /var/run/docker.sock On the slave machine add the in-bound rules to direct traffic to the port 8080 by updating the security groups on the AWS console as shown below. AWS console for slave machine Access the slave IP with the exposed port 8080 on the browser and the application should be up. Application running on port 8080 Hope the article was useful, thanks for reading! Happy learning. üëç Vrinda Hegde is a DevOps Engineer, who likes to explore orchestration tools and automate the process of deploying containerized applications. She likes to share her findings by writing articles on medium.com. She can be reached out on LinkedIn or via email Siya Amonkar is a DevOps Engineer who likes to explore new tools and technologies. She can be reached out on LinkedIn or via email ","date":"2022-06-03","objectID":"/docker_containters_ansibleaws/:8:0","tags":["How-to","docker","blog","ansible","aws","technology","VrindaHegde","SiyaAmonkar","VisitingAuthors"],"title":"Docker containers using Ansible on AWS","uri":"/docker_containters_ansibleaws/"},{"categories":["How-to","technology"],"content":" Nope! This is article is not about what AWS is, how it works and what are its services, rather it talks about AWS and how to get started with it being a complete beginner. I am working on AWS for more than 5+ years now and have taught professionally for 2 years, hence, I understand how overwhelming it might get for a beginner to figure out how to start studying AWS. For many, due to one or the other reasons, AWS is the first public cloud provider which they get exposed to. Hence, this article aims at providing you a detailed overview about AWS and its ecosystem and how to get started with it. I plan to write a similar blogpost on the other two major cloud providers, Google Cloud Platform [GCP] and Microsoft Azure, but that‚Äôs for another day once I myself get a good hold on them. This article is for a student, who is just starting with their cloud journey, or for a software developer, tester, technical sales who are new to AWS or cloud for that matter. If your team is looking to invest in AWS, or your company is undergoing digital transformation, or if you are a startup looking to migrate some/entire load on to AWS, then this article is for you. I hope this article serves you‚Äôll well. Let‚Äôs get started! ","date":"2022-06-03","objectID":"/aws_for_beginners/:0:0","tags":["How-to","blog","aws","technology"],"title":"How to get started on AWS","uri":"/aws_for_beginners/"},{"categories":["How-to","technology"],"content":"What is AWS? AWS stands for Amazon Web Services. It offers variety of models, the most famous being pay-as-you-go, to work with the basic infrastructure you would need to run your company. The services include range of products in the compute, storage, networking, database, analytics and many other domain. It is a comprehensive cloud computing platform that includes infrastructure as a service (IaaS), platform as a service (PaaS) as well as sofware as a service (SaaS) offerings. services ","date":"2022-06-03","objectID":"/aws_for_beginners/:1:0","tags":["How-to","blog","aws","technology"],"title":"How to get started on AWS","uri":"/aws_for_beginners/"},{"categories":["How-to","technology"],"content":"Start with core services AWS offers more than 150+ services, which can be quite intimidating for a beginner. However, you don‚Äôt need to master them all. You can start with the core services which acts as a building blocks of any cloud provider and also help you get certified eventually. I always recommend to start with Identity and Access Management (IAM) service for couple of reasons. Since it is absolutely free of cost: You get a good grasp of AWS console while exploring and learning IAM Even if you mess up with IAM, your account most probably will not get charged Below are some of the key ‚Äúbuilding block‚Äù services which form the core of the AWS platform. Getting familiar with these is a good place to start your learning: Elastic Compute Cloud (EC2): virtual servers Relational Database Service (RDS): relational databases Elastic Block Store (EBS): block storage Simple Storage Service (S3): file storage Identity and Access Management (IAM): users, groups and roles Virtual Private Cloud (VPC): networking Remember Learn core AWS services first Prioritise hands-on learning Structure your learning ","date":"2022-06-03","objectID":"/aws_for_beginners/:2:0","tags":["How-to","blog","aws","technology"],"title":"How to get started on AWS","uri":"/aws_for_beginners/"},{"categories":["How-to","technology"],"content":"Certifications Getting certified on AWS have great benefits and you don‚Äôt have to get certified on all of them. Depending on your role/domain/aspirations, you select a specific track and prepare for accordingly. The good thing is, AWS certificaion exams are simplified and borken down into different categories. Associate: The associate exams are your more entry level exams, Professional: The professional exams build on top of the associate exams with more detail. Specialty: You can also go down a specialty route and learning a specific topic like Networking or Security. AWS Certifications The best place to start as a complete beginner is with the Cloud Practitioner exam. The Cloud Practitioner exam is going to give you a solid basis in AWS. When you‚Äôve completed the Cloud Practitioner exam, you can then take a look at one of the associate exams, Architect, SysOps or Developer depending on your preference. ","date":"2022-06-03","objectID":"/aws_for_beginners/:3:0","tags":["How-to","blog","aws","technology"],"title":"How to get started on AWS","uri":"/aws_for_beginners/"},{"categories":["How-to","technology"],"content":"Resources Alright, since we have covered what AWS is, what are its services and what certifications AWS provides, I think it‚Äôs time to talk about the resources to master those services. Documentation youtube stackoverflow aws.amazon.com/free In addition to these resources, also checkout: ‚Ä¢ Whitepapers: Resources designed to broaden your technical understanding, written by the AWS team, independent analysts, and AWS partners. ‚Ä¢ FAQ: Commonly raised issues and questions that will help you understand AWS products, services, and features beyond the scope of your personal experience. ","date":"2022-06-03","objectID":"/aws_for_beginners/:4:0","tags":["How-to","blog","aws","technology"],"title":"How to get started on AWS","uri":"/aws_for_beginners/"},{"categories":["How-to","technology"],"content":"Prerequisites Before you start with hands-on practice, you need: AWS free tier account to kick off journey Credit card or debit card is mandatory ( It will not charge if you are using the free tier resources properly. Do checkout the free tier limit for the services you are working with). ","date":"2022-06-03","objectID":"/aws_for_beginners/:5:0","tags":["How-to","blog","aws","technology"],"title":"How to get started on AWS","uri":"/aws_for_beginners/"},{"categories":["How-to","technology"],"content":"Events AWS hosts events, both online and in-person, bringing the cloud computing community together to connect, collaborate, and learn from AWS experts. These events ranges from AWS Summits, to partner events, webinars, training and certification and more. Check out the events page for more details. ","date":"2022-06-03","objectID":"/aws_for_beginners/:6:0","tags":["How-to","blog","aws","technology"],"title":"How to get started on AWS","uri":"/aws_for_beginners/"},{"categories":["How-to","technology"],"content":"Careers AWS offers exciting and variety of roles around the globe. Check out the careers page for more details. Note: AWS frequently keeps adding new services to its current pool and reguarly comes up with new certifications. Also, the links that I have shared in this articles may get updated. If you come across any such instance, feel free to reach out to me so that it will help me keep this article updated. Happy learning! ","date":"2022-06-03","objectID":"/aws_for_beginners/:7:0","tags":["How-to","blog","aws","technology"],"title":"How to get started on AWS","uri":"/aws_for_beginners/"},{"categories":["How-to","VisitingAuthors","technology"],"content":"Recently, while working on an internal project I was required to ping a Windows server from a RHEL server. Sounds easy, right? It would have been indeed, however, the task was to ping the Windows server from RHEL via ansible, and that‚Äôs where the scenario got tricky. I went through a few articles and videos on and thought of documenting my learnings in this blog. Let‚Äôs start by getting to know the host requirements. Host requirements: For Ansible to communicate to a Windows host and use Windows modules, the Windows host must meet these requirements: Ansible can generally manage Windows versions under current and extended support from Microsoft. Ansible can manage desktop OSs including Windows 7, 8.1, and 10, and server OSs including Windows Server 2008, 2008 R2, 2012, 2012 R2, 2016, and 2019. Ansible requires PowerShell 3.0 or newer and at least .NET 4.0 to be installed on the Windows host. A WinRM listener should be created and activated. Use below steps to configure: ","date":"2022-05-26","objectID":"/ansible_sd/:0:0","tags":["How-to","technology","windows","Red Hat","RHEL","ansible","ShreyaDhange","VisitingAuthors"],"title":"Managing Windows Server from Red Hat Server using Ansible on AWS EC2","uri":"/ansible_sd/"},{"categories":["How-to","VisitingAuthors","technology"],"content":"1. Configure Windows server 2016: a. Open Windows PowerShell and check the version: PS C:\\Users\\Adminstrator\u003e Get-Host | Select-Object version powershell version The powershell version should at least be 3.0 or more. If not then upgrade it using this document. Since we have version 5.1 no need to upgrade the version. b. Once PowerShell has been upgraded, the final step is for the WinRM service to be configured so that Ansible can connect to it: PS C:\\Users\\Administrator\u003e [Net.ServicePointManager]::SecurityProtocol = [Net.SecurityProtocolType]::Tls12 PS C:\\Users\\Administrator\u003e $url = \"https://raw.githubusercontent.com/ansible/ansible/devel/examples/scripts/ConfigureRemotingForAnsible.ps1\"$file = \"$env:temp\\ConfigureRemotingForAnsible.ps1\" PS C:\\Users\\Administrator\u003e (New-Object -TypeName System.Net.WebClient).DownloadFile($url, $file) PS C:\\Users\\Administrator\u003e powershell.exe -ExecutionPolicy ByPass -File $file c. Run this below script on Windows PowerShell ISE and check the version after successful script completion: Param([string]$computerName) Function enableWinRM { $result = winrm id -r:$global:compName 2\u003e$null Write-Host if ($LastExitCode -eq 0) { Write-Host \"WinRM already enabled on\" $global:compName \"...\" -ForegroundColor green } else { Write-Host \"Enabling WinRM on\" $global:compName \"...\" -ForegroundColor red .\\pstools\\psexec.exe \\\\$global:compName -s C:\\Windows\\system32\\winrm.cmd qc -quiet if ($LastExitCode -eq 0) { .\\pstools\\psservice.exe \\\\$global:compName restart WinRM $result = winrm id -r:$global:compName 2\u003e$null if ($LastExitCode -eq 0) {Write-Host 'WinRM successfully enabled!' -ForegroundColor green} else {exit 1} } else {exit 1} } } $global:compName = $computerName enableWinRM exit 0 version after script completion d. Check if ports are listening: PS C:\\Users\\Administrator\u003e winrm enumerate winrm/config/Listener port listener ","date":"2022-05-26","objectID":"/ansible_sd/:1:0","tags":["How-to","technology","windows","Red Hat","RHEL","ansible","ShreyaDhange","VisitingAuthors"],"title":"Managing Windows Server from Red Hat Server using Ansible on AWS EC2","uri":"/ansible_sd/"},{"categories":["How-to","VisitingAuthors","technology"],"content":"2. Configure Red Hat 8 Server: a. If you have subscription manager account then subscribe your system using subscription-manager command: [root@ip-172-31-23-177 ~]# subscription-manager register b. Install ansible if package is not available: [root@ip-172-31-23-177 ~]# yum install ansible c. Install python-pip package: [root@ip-172-31-23-177 ~]# pip2 --version [root@ip-172-31-23-177 ~]# pip3 --version [root@ip-172-31-23-177 ~]# dnf install python2-pip [root@ip-172-31-23-177 ~]# dnf install python3-pip [root@ip-172-31-23-177 ~]# pip2 --version pip 9.0.3 from /usr/lib/python2.7/site-packages (python 2.7) [root@ip-172-31-23-177 ~]# pip3 --version pip 9.0.3 from /usr/lib/python3.6/site-packages (python 3.6) [root@ip-172-31-23-177 ~]# pip3 install \"pywinrm\u003e=0.2.2\" d. Now write a ansible playbook to ping windows server: [root@ip-172-31-23-177 ~]# tail /etc/ansible/hosts ## db-[99:101]-node.example.com [windows] 107.20.75.188 [windows:vars] ansible_user=\"windows_username\" //for example: ansible_user=\"Administrator\" ansible_password=\"windows_user_password\" ansible_connection=winrm ansible_winrm_server_cert_validation=ignore e. Use the below command to ping windows server: [root@ip-172-31-23-177 ansible]# ansible all -i hosts -m win_ping pinging windows server ","date":"2022-05-26","objectID":"/ansible_sd/:2:0","tags":["How-to","technology","windows","Red Hat","RHEL","ansible","ShreyaDhange","VisitingAuthors"],"title":"Managing Windows Server from Red Hat Server using Ansible on AWS EC2","uri":"/ansible_sd/"},{"categories":["How-to","VisitingAuthors","technology"],"content":"Resources: Setting up a Windows Host WinRM Setup WinRM setup script Linux and Windows host setup How to install pip in RHEL 8 / CentOS 8 step by step instructions Windows PowerShell Upgrade Ansible-windows-lab-setup (where ansible server is in linux and target node is in windows) Tip: RDP Port No: 3389 Shreya Dhange is a Technical Training Developer at Red Hat, who likes to explore and learn new technologies and share her knowledge by writing articles. She has completed her Masters in Computer Science and has gained award for her exemplary academic performance. She has been engaged in creating and delivering content in the cloud and linux space. She can be reached out LinkedIn or via email. ","date":"2022-05-26","objectID":"/ansible_sd/:3:0","tags":["How-to","technology","windows","Red Hat","RHEL","ansible","ShreyaDhange","VisitingAuthors"],"title":"Managing Windows Server from Red Hat Server using Ansible on AWS EC2","uri":"/ansible_sd/"}]